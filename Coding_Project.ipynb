{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_file_path = \"./ratebeer.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial pass at fixing data\n",
    "f = open(raw_data_file_path)\n",
    "s = f.read()\n",
    "s = s.replace('\"', \"'\")\n",
    "s = s.replace(\"\\\\\", \"\")\n",
    "s = re.sub(r\"'([a-zA-Z0-9\\/]+)':( ')\", r'\"\\1\":\\2', s)\n",
    "s = re.sub(r\": '(.*?)'(, \\\"|})\", r': \"\\1\"\\2', s)\n",
    "s = s.replace(\"}\", \"},\")\n",
    "s = \"[\" + s + \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge cases\n",
    "index1 = 1211756778\n",
    "sus = 5\n",
    "s = s[0:index1-sus] + \"'\" + s[index1-sus+1:]\n",
    "index2 = 1211757555\n",
    "sus = 3\n",
    "s = s[0:index2-sus] + '\"' + s[index2-sus+1:]\n",
    "index3 = 1931627431\n",
    "sus = 2\n",
    "s = s[0:index3-sus] + s[index3-sus+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as new json file\n",
    "json_object = json.dumps(data, indent=4)\n",
    "with open(\"./beer_data.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in fixed json file from now on\n",
    "data_file_path = './beer_data.json'\n",
    "df_full = pd.read_json(data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_expr(expr):\n",
    "    try:\n",
    "        return eval(expr)\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build new columns with float values instead of string expressions\n",
    "df_full['appearance'] = df_full.apply(lambda row : eval_expr(row['review/appearance']), axis=1)\n",
    "df_full['aroma'] = df_full.apply(lambda row : eval_expr(row['review/aroma']), axis=1)\n",
    "df_full['palate'] = df_full.apply(lambda row : eval_expr(row['review/palate']), axis=1)\n",
    "df_full['taste'] = df_full.apply(lambda row : eval_expr(row['review/taste']), axis=1)\n",
    "df_full['overall'] = df_full.apply(lambda row : eval_expr(row['review/overall']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full[(df_full['overall'] >= 0) & (df_full['beer/ABV'] != '-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_names = df_full['beer/name'].unique()\n",
    "beer_styles = df_full['beer/style'].unique()\n",
    "beer_style_index = dict(zip(beer_styles, range(len(beer_styles))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxyuan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/maxyuan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# build new abv column with float values instead of strings and also a beer style column with an index instead of string\n",
    "df_full['abv'] = df_full.apply(lambda row: float(row['beer/ABV']), axis=1)\n",
    "df_full['style'] = df_full.apply(lambda row: beer_style_index[row['beer/style']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_rating = df_full[df_full['overall'] > 0.5]\n",
    "negative_rating = df_full[df_full['overall'] <= 0.5]\n",
    "\n",
    "high_rating = df_full[df_full['overall'] > 0.7]\n",
    "med_rating = df_full[(df_full['overall'] >= 0.4) & (df_full['overall'] <= 0.7)]\n",
    "low_rating = df_full[df_full['overall'] < 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2299884\n",
      "485642\n",
      "1100450\n",
      "1501568\n",
      "183508\n"
     ]
    }
   ],
   "source": [
    "print(len(positive_rating.index))\n",
    "print(len(negative_rating.index))\n",
    "\n",
    "print(len(high_rating.index))\n",
    "print(len(med_rating.index))\n",
    "print(len(low_rating.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset with equal number of the different kinds ratings\n",
    "NUM_SAMPLES = 18000\n",
    "NUM_SAMPLES_WITH_PADDING = NUM_SAMPLES + 300 # we remove empty reviews later so this allows space for that\n",
    "positive_indices = random.sample(positive_rating.index.tolist(), int(NUM_SAMPLES_WITH_PADDING / 2))\n",
    "negative_indices = random.sample(negative_rating.index.tolist(), int(NUM_SAMPLES_WITH_PADDING / 2))\n",
    "\n",
    "high_indices = random.sample(high_rating.index.tolist(), int(NUM_SAMPLES_WITH_PADDING / 3))\n",
    "med_indices = random.sample(med_rating.index.tolist(), int(NUM_SAMPLES_WITH_PADDING / 3))\n",
    "low_indices = random.sample(low_rating.index.tolist(), int(NUM_SAMPLES_WITH_PADDING / 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _b means binary rating, which is just positive or negative\n",
    "# _t means ternary rating, which is high, medium, and low\n",
    "rows_b = positive_indices + negative_indices\n",
    "rows_t = high_indices + med_indices +low_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = df_full.iloc[rows_b]\n",
    "df_t = df_full.iloc[rows_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18300, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer/name</th>\n",
       "      <th>beer/beerId</th>\n",
       "      <th>beer/brewerId</th>\n",
       "      <th>beer/ABV</th>\n",
       "      <th>beer/style</th>\n",
       "      <th>review/appearance</th>\n",
       "      <th>review/aroma</th>\n",
       "      <th>review/palate</th>\n",
       "      <th>review/taste</th>\n",
       "      <th>review/overall</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/profileName</th>\n",
       "      <th>review/text</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>abv</th>\n",
       "      <th>style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1715141</td>\n",
       "      <td>Bells Oberon Ale</td>\n",
       "      <td>3211</td>\n",
       "      <td>232.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Wheat Ale</td>\n",
       "      <td>5/5</td>\n",
       "      <td>7/10</td>\n",
       "      <td>4/5</td>\n",
       "      <td>8/10</td>\n",
       "      <td>15/20</td>\n",
       "      <td>1.038096e+09</td>\n",
       "      <td>Andrew196</td>\n",
       "      <td>Probably the best wheat beer I have had in a l...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672442</td>\n",
       "      <td>Ridgeway Foreign Export Stout</td>\n",
       "      <td>70803</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Foreign Stout</td>\n",
       "      <td>4/5</td>\n",
       "      <td>6/10</td>\n",
       "      <td>3/5</td>\n",
       "      <td>6/10</td>\n",
       "      <td>13/20</td>\n",
       "      <td>1.200874e+09</td>\n",
       "      <td>MesandSim</td>\n",
       "      <td>UPDATED: AUG 28, 2008 A Mes rate: Bottle at my...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8.0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>631026</td>\n",
       "      <td>Cigar City Extra Sour Guava Grove</td>\n",
       "      <td>136408</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Sour Ale/Wild Ale</td>\n",
       "      <td>3/5</td>\n",
       "      <td>7/10</td>\n",
       "      <td>3/5</td>\n",
       "      <td>8/10</td>\n",
       "      <td>15/20</td>\n",
       "      <td>1.324598e+09</td>\n",
       "      <td>sebletitje</td>\n",
       "      <td>Entering old rates. Bottle shared with Wayne @...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1537341</td>\n",
       "      <td>Victory Dark Intrigue</td>\n",
       "      <td>132106</td>\n",
       "      <td>101.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Imperial Stout</td>\n",
       "      <td>4/5</td>\n",
       "      <td>7/10</td>\n",
       "      <td>4/5</td>\n",
       "      <td>7/10</td>\n",
       "      <td>15/20</td>\n",
       "      <td>1.303085e+09</td>\n",
       "      <td>Fin</td>\n",
       "      <td>Bottle at Jan &amp; Charlottes tasting, Ulfborg,...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1062334</td>\n",
       "      <td>Founders Double Trouble IPA</td>\n",
       "      <td>67360</td>\n",
       "      <td>554.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>Imperial/Double IPA</td>\n",
       "      <td>4/5</td>\n",
       "      <td>8/10</td>\n",
       "      <td>4/5</td>\n",
       "      <td>8/10</td>\n",
       "      <td>17/20</td>\n",
       "      <td>1.241309e+09</td>\n",
       "      <td>ApisAles</td>\n",
       "      <td>Really solid IPA.  Had it on tap at RFD in D.C...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.85</td>\n",
       "      <td>9.4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 beer/name beer/beerId  beer/brewerId  \\\n",
       "1715141                   Bells Oberon Ale        3211          232.0   \n",
       "672442       Ridgeway Foreign Export Stout       70803         1265.0   \n",
       "631026   Cigar City Extra Sour Guava Grove      136408         9990.0   \n",
       "1537341              Victory Dark Intrigue      132106          101.0   \n",
       "1062334        Founders Double Trouble IPA       67360          554.0   \n",
       "\n",
       "        beer/ABV           beer/style review/appearance review/aroma  \\\n",
       "1715141        6            Wheat Ale               5/5         7/10   \n",
       "672442         8        Foreign Stout               4/5         6/10   \n",
       "631026         8    Sour Ale/Wild Ale               3/5         7/10   \n",
       "1537341      9.1       Imperial Stout               4/5         7/10   \n",
       "1062334      9.4  Imperial/Double IPA               4/5         8/10   \n",
       "\n",
       "        review/palate review/taste review/overall   review/time  \\\n",
       "1715141           4/5         8/10          15/20  1.038096e+09   \n",
       "672442            3/5         6/10          13/20  1.200874e+09   \n",
       "631026            3/5         8/10          15/20  1.324598e+09   \n",
       "1537341           4/5         7/10          15/20  1.303085e+09   \n",
       "1062334           4/5         8/10          17/20  1.241309e+09   \n",
       "\n",
       "        review/profileName                                        review/text  \\\n",
       "1715141          Andrew196  Probably the best wheat beer I have had in a l...   \n",
       "672442           MesandSim  UPDATED: AUG 28, 2008 A Mes rate: Bottle at my...   \n",
       "631026          sebletitje  Entering old rates. Bottle shared with Wayne @...   \n",
       "1537341                Fin    Bottle at Jan & Charlottes tasting, Ulfborg,...   \n",
       "1062334           ApisAles  Really solid IPA.  Had it on tap at RFD in D.C...   \n",
       "\n",
       "         appearance  aroma  palate  taste  overall  abv  style  \n",
       "1715141         1.0    0.7     0.8    0.8     0.75  6.0     21  \n",
       "672442          0.8    0.6     0.6    0.6     0.65  8.0     69  \n",
       "631026          0.6    0.7     0.6    0.8     0.75  8.0     23  \n",
       "1537341         0.8    0.7     0.8    0.7     0.75  9.1     13  \n",
       "1062334         0.8    0.8     0.8    0.8     0.85  9.4      7  "
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_b.shape)\n",
    "df_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18300, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer/name</th>\n",
       "      <th>beer/beerId</th>\n",
       "      <th>beer/brewerId</th>\n",
       "      <th>beer/ABV</th>\n",
       "      <th>beer/style</th>\n",
       "      <th>review/appearance</th>\n",
       "      <th>review/aroma</th>\n",
       "      <th>review/palate</th>\n",
       "      <th>review/taste</th>\n",
       "      <th>review/overall</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/profileName</th>\n",
       "      <th>review/text</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>abv</th>\n",
       "      <th>style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1688104</td>\n",
       "      <td>Bells Java Stout</td>\n",
       "      <td>10338</td>\n",
       "      <td>232.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Stout</td>\n",
       "      <td>4/5</td>\n",
       "      <td>9/10</td>\n",
       "      <td>5/5</td>\n",
       "      <td>8/10</td>\n",
       "      <td>15/20</td>\n",
       "      <td>1.214266e+09</td>\n",
       "      <td>lunchbox582</td>\n",
       "      <td>12 oz bought from the brewery in a mixed sixer...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>7.5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330058</td>\n",
       "      <td>Pinkus Hefe Weizen</td>\n",
       "      <td>4552</td>\n",
       "      <td>742.0</td>\n",
       "      <td>5</td>\n",
       "      <td>German Hefeweizen</td>\n",
       "      <td>4/5</td>\n",
       "      <td>8/10</td>\n",
       "      <td>4/5</td>\n",
       "      <td>8/10</td>\n",
       "      <td>17/20</td>\n",
       "      <td>1.012349e+09</td>\n",
       "      <td>wheatbeerboy</td>\n",
       "      <td>A really different tasting hefeweizen. I could...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1792395</td>\n",
       "      <td>Leelanau Whaleback White</td>\n",
       "      <td>49308</td>\n",
       "      <td>4923.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Belgian White &amp;#40;Witbier&amp;#41;</td>\n",
       "      <td>4/5</td>\n",
       "      <td>7/10</td>\n",
       "      <td>4/5</td>\n",
       "      <td>8/10</td>\n",
       "      <td>16/20</td>\n",
       "      <td>1.168992e+09</td>\n",
       "      <td>thebaldwizard</td>\n",
       "      <td>Shared at C-bus tasting 5.  I wish all Wits ta...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1114182</td>\n",
       "      <td>Sierra Nevada Hoptimum</td>\n",
       "      <td>117825</td>\n",
       "      <td>67.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>Imperial/Double IPA</td>\n",
       "      <td>4/5</td>\n",
       "      <td>7/10</td>\n",
       "      <td>4/5</td>\n",
       "      <td>7/10</td>\n",
       "      <td>16/20</td>\n",
       "      <td>1.284422e+09</td>\n",
       "      <td>JohnnyJ</td>\n",
       "      <td>Draft at the brewery.  Golden amber pour, whit...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1008245</td>\n",
       "      <td>Samuel Adams Imperial Series Double Bock</td>\n",
       "      <td>96144</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Doppelbock</td>\n",
       "      <td>3/5</td>\n",
       "      <td>7/10</td>\n",
       "      <td>3/5</td>\n",
       "      <td>7/10</td>\n",
       "      <td>16/20</td>\n",
       "      <td>1.236384e+09</td>\n",
       "      <td>emacgee</td>\n",
       "      <td>Pours a dark ruby copper with a thin light tan...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.80</td>\n",
       "      <td>9.5</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        beer/name beer/beerId  beer/brewerId  \\\n",
       "1688104                          Bells Java Stout       10338          232.0   \n",
       "330058                         Pinkus Hefe Weizen        4552          742.0   \n",
       "1792395                  Leelanau Whaleback White       49308         4923.0   \n",
       "1114182                    Sierra Nevada Hoptimum      117825           67.0   \n",
       "1008245  Samuel Adams Imperial Series Double Bock       96144           32.0   \n",
       "\n",
       "        beer/ABV                       beer/style review/appearance  \\\n",
       "1688104      7.5                            Stout               4/5   \n",
       "330058         5                German Hefeweizen               4/5   \n",
       "1792395      5.2  Belgian White &#40;Witbier&#41;               4/5   \n",
       "1114182     10.4              Imperial/Double IPA               4/5   \n",
       "1008245      9.5                       Doppelbock               3/5   \n",
       "\n",
       "        review/aroma review/palate review/taste review/overall   review/time  \\\n",
       "1688104         9/10           5/5         8/10          15/20  1.214266e+09   \n",
       "330058          8/10           4/5         8/10          17/20  1.012349e+09   \n",
       "1792395         7/10           4/5         8/10          16/20  1.168992e+09   \n",
       "1114182         7/10           4/5         7/10          16/20  1.284422e+09   \n",
       "1008245         7/10           3/5         7/10          16/20  1.236384e+09   \n",
       "\n",
       "        review/profileName                                        review/text  \\\n",
       "1688104        lunchbox582  12 oz bought from the brewery in a mixed sixer...   \n",
       "330058        wheatbeerboy  A really different tasting hefeweizen. I could...   \n",
       "1792395      thebaldwizard  Shared at C-bus tasting 5.  I wish all Wits ta...   \n",
       "1114182            JohnnyJ  Draft at the brewery.  Golden amber pour, whit...   \n",
       "1008245            emacgee  Pours a dark ruby copper with a thin light tan...   \n",
       "\n",
       "         appearance  aroma  palate  taste  overall   abv  style  \n",
       "1688104         0.8    0.9     1.0    0.8     0.75   7.5     16  \n",
       "330058          0.8    0.8     0.8    0.8     0.85   5.0     30  \n",
       "1792395         0.8    0.7     0.8    0.8     0.80   5.2     36  \n",
       "1114182         0.8    0.7     0.8    0.7     0.80  10.4      7  \n",
       "1008245         0.6    0.7     0.6    0.7     0.80   9.5     38  "
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_t.shape)\n",
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation from reviews\n",
    "reviews_b = df_b['review/text'].values.tolist()\n",
    "reviews_b = [review.translate(str.maketrans('','',punctuation)).lower() for review in reviews_b]\n",
    "\n",
    "reviews_t = df_t['review/text'].values.tolist()\n",
    "reviews_t = [review.translate(str.maketrans('','',punctuation)).lower() for review in reviews_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocab from words in reviews\n",
    "\n",
    "all_reviews_b = ' '.join(reviews_b)\n",
    "words_b = all_reviews_b.split()\n",
    "word_to_count_b = Counter(words_b)\n",
    "words_sorted_b = word_to_count_b.most_common(len(words_b))\n",
    "word_to_index_b = {word:index+1 for index, (word,count) in enumerate(words_sorted_b)}\n",
    "\n",
    "all_reviews_t = ' '.join(reviews_t)\n",
    "words_t = all_reviews_t.split()\n",
    "word_to_count_t = Counter(words_t)\n",
    "words_sorted_t = word_to_count_t.most_common(len(words_t))\n",
    "word_to_index_t = {word:index+1 for index, (word,count) in enumerate(words_sorted_t)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize reviews\n",
    "reviews_tokenized_og_b = [[word_to_index_b[word] for word in review.split()] for review in reviews_b]\n",
    "reviews_tokenized_og_t = [[word_to_index_t[word] for word in review.split()] for review in reviews_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9150, 9150]\n",
      "[6100, 6100, 6100]\n"
     ]
    }
   ],
   "source": [
    "# build labels\n",
    "overall_ratings_b = df_b['overall'].values.tolist()\n",
    "binary_labels_og = [1 if rating > 0.5 else 0 for rating in overall_ratings_b]\n",
    "\n",
    "overall_ratings_t = df_t['overall'].values.tolist()\n",
    "ternary_labels_og = [2 if rating > 0.7 else (0 if rating < 0.4 else 1) for rating in overall_ratings_t]\n",
    "\n",
    "print([binary_labels_og.count(x) for x in range(2)])\n",
    "print([ternary_labels_og.count(x) for x in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    18300.000000\n",
       "mean        49.345902\n",
       "std         35.626908\n",
       "min          0.000000\n",
       "25%         27.000000\n",
       "50%         40.000000\n",
       "75%         60.000000\n",
       "max        570.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how long reviews are to determine sequence length for LSTM model\n",
    "\n",
    "reviews_len_b = [len(x) for x in reviews_tokenized_og_b]\n",
    "pd.Series(reviews_len_b).hist()\n",
    "plt.show()\n",
    "pd.Series(reviews_len_b).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    18300.000000\n",
       "mean        50.530929\n",
       "std         36.861034\n",
       "min          0.000000\n",
       "25%         28.000000\n",
       "50%         41.000000\n",
       "75%         62.000000\n",
       "max        655.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_len_t = [len(x) for x in reviews_tokenized_og_t]\n",
    "pd.Series(reviews_len_t).hist()\n",
    "plt.show()\n",
    "pd.Series(reviews_len_t).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove reviews that are empty\n",
    "reviews_tokenized_og_b = [reviews_tokenized_og_b[i] for i, length in enumerate(reviews_len_b) if length > 0]\n",
    "reviews_tokenized_og_t = [reviews_tokenized_og_t[i] for i, length in enumerate(reviews_len_t) if length > 0]\n",
    "\n",
    "binary_labels_og = [binary_labels_og[i] for i, length in enumerate(reviews_len_b) if length > 0]\n",
    "ternary_labels_og = [ternary_labels_og[i] for i, length in enumerate(reviews_len_t) if length > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tokens(reviews, seq_length):\n",
    "    # pad beginning of tokens with 0 or truncate to seq_length\n",
    "    features = np.zeros((len(reviews), seq_length), dtype = int)\n",
    "    \n",
    "    for index, tokens in enumerate(reviews):\n",
    "        if len(tokens) != 0:\n",
    "            features[index, -(min(seq_length, len(tokens))):] = np.array(tokens)[:min(seq_lenth, len(tokens))]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_og_b = pad_tokens(reviews_tokenized_og_b, 200)\n",
    "features_og_t = pad_tokens(reviews_tokenized_og_t, 200)\n",
    "\n",
    "binary_labels_og=np.array(binary_labels_og)\n",
    "ternary_labels_og=np.array(ternary_labels_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 200)\n",
      "(18000, 200)\n",
      "(18000,)\n",
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "# cut back down to NUM_SAMPLES after removing empty reviews\n",
    "\n",
    "num_features_og_b = len(features_og_b)\n",
    "num_features_og_t = len(features_og_t)\n",
    "\n",
    "random_subset_b = random.sample(range(num_features_og_b), NUM_SAMPLES)\n",
    "random_subset_t = random.sample(range(num_features_og_t), NUM_SAMPLES)\n",
    "\n",
    "features_b = features_og_b[random_subset_b,]\n",
    "binary_labels = binary_labels_og[random_subset_b]\n",
    "\n",
    "features_t = features_og_t[random_subset_t,]\n",
    "ternary_labels = ternary_labels_og[random_subset_t]\n",
    "\n",
    "print(features_b.shape)\n",
    "print(features_t.shape)\n",
    "print(binary_labels.shape)\n",
    "print(ternary_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4976111111111111\n",
      "0.3298333333333333\n"
     ]
    }
   ],
   "source": [
    "# how good is random guessing?\n",
    "\n",
    "print(np.mean(binary_labels==random.choices(range(2), k=len(binary_labels))))\n",
    "print(np.mean(ternary_labels==random.choices(range(3), k=len(ternary_labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build train, validate, and test sets\n",
    "\n",
    "split_frac = 0.8\n",
    "num_features = len(features_b)\n",
    "train_x_b = features_b[0:int(split_frac*num_features)]\n",
    "train_x_t = features_t[0:int(split_frac*num_features)]\n",
    "train_y_b = binary_labels[0:int(split_frac*num_features)]\n",
    "train_y_t = ternary_labels[0:int(split_frac*num_features)]\n",
    "\n",
    "remaining_x_b = features_b[int(split_frac*num_features):]\n",
    "remaining_x_t = features_t[int(split_frac*num_features):]\n",
    "remaining_y_b = binary_labels[int(split_frac*num_features):]\n",
    "remaining_y_t = ternary_labels[int(split_frac*num_features):]\n",
    "\n",
    "valid_x_b = remaining_x_b[0:int(len(remaining_x_b)*0.5)]\n",
    "valid_x_t = remaining_x_t[0:int(len(remaining_x_t)*0.5)]\n",
    "valid_y_b = remaining_y_b[0:int(len(remaining_y_b)*0.5)]\n",
    "valid_y_t = remaining_y_t[0:int(len(remaining_y_t)*0.5)]\n",
    "\n",
    "test_x_b = remaining_x_b[int(len(remaining_x_b)*0.5):]\n",
    "test_x_t = remaining_x_t[int(len(remaining_x_t)*0.5):]\n",
    "test_y_b = remaining_y_b[int(len(remaining_y_b)*0.5):]\n",
    "test_y_t = remaining_y_t[int(len(remaining_y_t)*0.5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    # LSTM for sentiment analysis\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        output_size,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, hidden_dim, 2, dropout=0.5, batch_first=True\n",
    "        )\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # fully connected linear layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "        # sigmoid layer for the binary sentiment analysis case\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        # softmax layer for the ternary sentiment analysis case\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "\n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "\n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid or softmax function\n",
    "        prob_out = self.sig(out) if self.output_size == 1 else self.softmax(out)\n",
    "\n",
    "        # reshape to be batch_size as first dimension\n",
    "        if self.output_size == 1:\n",
    "            prob_out = prob_out.view(batch_size, -1)\n",
    "            prob_out = prob_out[:, -1]  # get last batch of labels\n",
    "        else:\n",
    "            prob_out = prob_out.view(batch_size, -1, self.output_size)\n",
    "            prob_out = prob_out[:, -1, :] # get last batch of labels\n",
    "        \n",
    "\n",
    "        # return last sigmoid/softmax output and hidden state\n",
    "        return prob_out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # create 2 tensors with sizes 2 x batch_size x hidden_dim,\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        # initialized hidden state to 0\n",
    "        hidden = (\n",
    "            weight.new(2, batch_size, self.hidden_dim).zero_(),\n",
    "            weight.new(2, batch_size, self.hidden_dim).zero_(),\n",
    "        )\n",
    "\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "# create datasets\n",
    "train_data_b = TensorDataset(torch.from_numpy(train_x_b), torch.from_numpy(train_y_b))\n",
    "valid_data_b = TensorDataset(torch.from_numpy(valid_x_b), torch.from_numpy(valid_y_b))\n",
    "test_data_b = TensorDataset(torch.from_numpy(test_x_b), torch.from_numpy(test_y_b))\n",
    "\n",
    "train_data_t = TensorDataset(torch.from_numpy(train_x_t), torch.from_numpy(train_y_t))\n",
    "valid_data_t = TensorDataset(torch.from_numpy(valid_x_t), torch.from_numpy(valid_y_t))\n",
    "test_data_t = TensorDataset(torch.from_numpy(test_x_t), torch.from_numpy(test_y_t))\n",
    "\n",
    "# dataloaders\n",
    "train_loader_b = DataLoader(train_data_b, shuffle=True, batch_size=batch_size)\n",
    "valid_loader_b = DataLoader(valid_data_b, shuffle=True, batch_size=batch_size)\n",
    "test_loader_b = DataLoader(test_data_b, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "train_loader_t = DataLoader(train_data_t, shuffle=True, batch_size=batch_size)\n",
    "valid_loader_t = DataLoader(valid_data_t, shuffle=True, batch_size=batch_size)\n",
    "test_loader_t = DataLoader(test_data_t, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentLSTM(\n",
      "  (embedding): Embedding(36592, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "SentimentLSTM(\n",
      "  (embedding): Embedding(37244, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (sig): Sigmoid()\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the two models\n",
    "vocab_size_b = len(word_to_index_b)+1\n",
    "vocab_size_t = len(word_to_index_t)+1\n",
    "output_size_b = 1\n",
    "output_size_t = 3\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "net_b = SentimentLSTM(vocab_size_b, output_size_b, embedding_dim, hidden_dim)\n",
    "net_t = SentimentLSTM(vocab_size_t, output_size_t, embedding_dim, hidden_dim)\n",
    "print(net_b)\n",
    "print(net_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 50... Accuracy: 0.700000... Loss: 0.597491... Val Accuracy: 0.707000... Val Loss: 0.570098\n",
      "Epoch: 1/4... Step: 100... Accuracy: 0.600000... Loss: 0.647017... Val Accuracy: 0.714600... Val Loss: 0.560543\n",
      "Epoch: 1/4... Step: 150... Accuracy: 0.820000... Loss: 0.478556... Val Accuracy: 0.739200... Val Loss: 0.532575\n",
      "Epoch: 2/4... Step: 200... Accuracy: 0.840000... Loss: 0.373601... Val Accuracy: 0.754800... Val Loss: 0.506916\n",
      "Epoch: 2/4... Step: 250... Accuracy: 0.900000... Loss: 0.342841... Val Accuracy: 0.773600... Val Loss: 0.486545\n",
      "Epoch: 2/4... Step: 300... Accuracy: 0.780000... Loss: 0.371110... Val Accuracy: 0.783400... Val Loss: 0.485738\n",
      "Epoch: 3/4... Step: 350... Accuracy: 0.920000... Loss: 0.246705... Val Accuracy: 0.778400... Val Loss: 0.504856\n",
      "Epoch: 3/4... Step: 400... Accuracy: 0.820000... Loss: 0.370458... Val Accuracy: 0.769200... Val Loss: 0.487841\n",
      "Epoch: 3/4... Step: 450... Accuracy: 0.820000... Loss: 0.399457... Val Accuracy: 0.773600... Val Loss: 0.496526\n",
      "Epoch: 4/4... Step: 500... Accuracy: 0.920000... Loss: 0.172422... Val Accuracy: 0.779800... Val Loss: 0.558085\n",
      "Epoch: 4/4... Step: 550... Accuracy: 0.920000... Loss: 0.182721... Val Accuracy: 0.780800... Val Loss: 0.570863\n",
      "Epoch: 4/4... Step: 600... Accuracy: 0.900000... Loss: 0.235190... Val Accuracy: 0.773200... Val Loss: 0.614002\n"
     ]
    }
   ],
   "source": [
    "# TRAINING FOR BINARY SENTIMENT ANALYSIS\n",
    "\n",
    "# loss and optimization functions\n",
    "lr=1e-3\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net_b.parameters(), lr=lr)\n",
    "\n",
    "# training params\n",
    "epochs = 4\n",
    "counter = 0\n",
    "print_every = 50\n",
    "clip=5 # gradient clipping\n",
    "epoch_accuracies = []\n",
    "\n",
    "net_b.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net_b.init_hidden(batch_size)\n",
    "    \n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader_b:\n",
    "        counter += 1\n",
    "        # copy hidden state\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero gradients\n",
    "        net_b.zero_grad()\n",
    "\n",
    "        # get predicted output\n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        output, h = net_b(inputs, h)\n",
    "        \n",
    "        # calculate accuracy for this step\n",
    "        preds = torch.round(output.squeeze())\n",
    "        mask = preds[preds == labels]\n",
    "        train_correct = len(mask)\n",
    "        train_total = len(labels)\n",
    "        \n",
    "        epoch_correct += train_correct\n",
    "        epoch_total += train_total\n",
    "\n",
    "        # calculate loss and backprop\n",
    "        loss = loss_fn(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "\n",
    "        # prevent exploding gradient problem in LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net_b.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # print stats\n",
    "        if counter % print_every == 0:\n",
    "            val_h = net_b.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net_b.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            for inputs, labels in valid_loader_b:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                inputs = inputs.type(torch.LongTensor)\n",
    "                output, val_h = net_b(inputs, val_h)\n",
    "                \n",
    "                preds = torch.round(output.squeeze())\n",
    "                mask = preds[preds == labels]\n",
    "                val_correct += len(mask)\n",
    "                val_total += len(labels)\n",
    "                \n",
    "                val_loss = loss_fn(output.squeeze(), labels.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net_b.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Accuracy: {:.6f}...\".format(float(train_correct)/train_total),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Accuracy: {:.6f}...\".format(float(val_correct) / val_total),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "\n",
    "    epoch_accuracies.append(float(epoch_correct) / epoch_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 Accuracy: 68.150%\n",
      "Epoch #2 Accuracy: 79.350%\n",
      "Epoch #3 Accuracy: 85.112%\n",
      "Epoch #4 Accuracy: 90.438%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(epoch_accuracies)):\n",
    "    print(\"Epoch #{} Accuracy: {:.3f}%\".format(i + 1, epoch_accuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.765\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net_b.init_hidden(batch_size)\n",
    "\n",
    "net_b.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader_b:\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    # get predicted outputs\n",
    "    inputs = inputs.type(torch.LongTensor)\n",
    "    output, h = net_b(inputs, h)\n",
    "\n",
    "    # get predicted class from output probabilities\n",
    "    preds = torch.round(output.squeeze())\n",
    "    mask = preds[preds == labels]\n",
    "    num_correct += len(mask)\n",
    "\n",
    "# test accuracy\n",
    "print(\"Test accuracy: {:.3f}\".format(float(num_correct)/len(test_loader_b.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 50... Accuracy: 0.520000... Loss: 0.974587... Val Accuracy: 0.519600... Val Loss: 0.995337\n",
      "Epoch: 1/4... Step: 100... Accuracy: 0.380000... Loss: 1.142842... Val Accuracy: 0.487800... Val Loss: 1.039565\n",
      "Epoch: 1/4... Step: 150... Accuracy: 0.580000... Loss: 0.963992... Val Accuracy: 0.579600... Val Loss: 0.958414\n",
      "Epoch: 2/4... Step: 200... Accuracy: 0.460000... Loss: 1.053802... Val Accuracy: 0.573200... Val Loss: 0.963046\n",
      "Epoch: 2/4... Step: 250... Accuracy: 0.640000... Loss: 0.899877... Val Accuracy: 0.594600... Val Loss: 0.934599\n",
      "Epoch: 2/4... Step: 300... Accuracy: 0.580000... Loss: 0.951416... Val Accuracy: 0.567200... Val Loss: 0.962075\n",
      "Epoch: 3/4... Step: 350... Accuracy: 0.680000... Loss: 0.867643... Val Accuracy: 0.623200... Val Loss: 0.911001\n",
      "Epoch: 3/4... Step: 400... Accuracy: 0.600000... Loss: 0.946137... Val Accuracy: 0.620600... Val Loss: 0.912677\n",
      "Epoch: 3/4... Step: 450... Accuracy: 0.700000... Loss: 0.866722... Val Accuracy: 0.584200... Val Loss: 0.942597\n",
      "Epoch: 4/4... Step: 500... Accuracy: 0.800000... Loss: 0.774280... Val Accuracy: 0.601400... Val Loss: 0.928646\n",
      "Epoch: 4/4... Step: 550... Accuracy: 0.640000... Loss: 0.904936... Val Accuracy: 0.615400... Val Loss: 0.921543\n",
      "Epoch: 4/4... Step: 600... Accuracy: 0.680000... Loss: 0.854530... Val Accuracy: 0.621200... Val Loss: 0.915683\n"
     ]
    }
   ],
   "source": [
    "# TRAINING FOR TERNARY SENTIMENT ANALYSIS\n",
    "\n",
    "# loss and optimization functions\n",
    "lr=1e-3\n",
    "# loss_fn = nn.BCELoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net_t.parameters(), lr=lr)\n",
    "\n",
    "# training params\n",
    "epochs = 4\n",
    "counter = 0\n",
    "print_every = 50\n",
    "clip=5 # gradient clipping\n",
    "epoch_accuracies = []\n",
    "\n",
    "net_t.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net_t.init_hidden(batch_size)\n",
    "    \n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader_t:\n",
    "        counter += 1\n",
    "        # copy hidden state\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero gradients\n",
    "        net_t.zero_grad()\n",
    "\n",
    "        # get predicted output\n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        output, h = net_t(inputs, h)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        \n",
    "        # calculate accuracy for this step\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        mask = preds[preds == labels]\n",
    "        train_correct = len(mask)\n",
    "        train_total = len(labels)\n",
    "        \n",
    "        epoch_correct += train_correct\n",
    "        epoch_total += train_total\n",
    "\n",
    "        # calculate loss and backprop\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # prevent exploding gradient problem in LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net_t.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # print stats\n",
    "        if counter % print_every == 0:\n",
    "            val_h = net_t.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net_t.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            for inputs, labels in valid_loader_t:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                inputs = inputs.type(torch.LongTensor)\n",
    "                output, val_h = net_t(inputs, val_h)\n",
    "                \n",
    "                preds = torch.argmax(output, dim=1)\n",
    "                mask = preds[preds == labels]\n",
    "                val_correct += len(mask)\n",
    "                val_total += len(labels)\n",
    "                \n",
    "                val_loss = loss_fn(output, labels)\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net_t.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Accuracy: {:.6f}...\".format(float(train_correct)/train_total),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Accuracy: {:.6f}...\".format(float(val_correct) / val_total),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "\n",
    "    epoch_accuracies.append(float(epoch_correct) / epoch_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 Accuracy: 50.825%\n",
      "Epoch #2 Accuracy: 61.113%\n",
      "Epoch #3 Accuracy: 66.663%\n",
      "Epoch #4 Accuracy: 70.837%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(epoch_accuracies)):\n",
    "    print(\"Epoch #{} Accuracy: {:.3f}%\".format(i + 1, epoch_accuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.623\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net_t.init_hidden(batch_size)\n",
    "\n",
    "net_t.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader_t:\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    # get predicted outputs\n",
    "    inputs = inputs.type(torch.LongTensor)\n",
    "    output, h = net_t(inputs, h)\n",
    "\n",
    "    # get predicted class from output probabilities\n",
    "    preds = torch.argmax(output, dim=1)\n",
    "    mask = preds[preds == labels]\n",
    "    num_correct += len(mask)\n",
    "\n",
    "# test accuracy\n",
    "print(\"Test accuracy: {:.3f}\".format(float(num_correct)/len(test_loader_b.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "abvs = df_full['abv'].values.tolist()\n",
    "styles = df_full['style'].values.tolist()\n",
    "ratings = df_full['overall'].values.tolist()\n",
    "taste_ratings = df_full['taste'].values.tolist()\n",
    "times = df_full['review/time'].values.tolist()\n",
    "reviewers = df_full['review/profileName'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewers_unique = df_full['review/profileName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_times = {}\n",
    "max_times = {}\n",
    "\n",
    "for i in range(len(times)):\n",
    "    name = reviewers[i]\n",
    "    time = times[i]\n",
    "    if not name in min_times:\n",
    "        min_times[name] = time\n",
    "    if not name in max_times:\n",
    "        max_times[name] = time\n",
    "    min_times[name] = min(time, min_times[name])\n",
    "    max_times[name] = max(time, max_times[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['experience'] = df_full.apply(lambda row : (row['review/time'] - min_times[row['review/profileName']]) / (60*60*24), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = df_full['experience'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer/name</th>\n",
       "      <th>beer/beerId</th>\n",
       "      <th>beer/brewerId</th>\n",
       "      <th>beer/ABV</th>\n",
       "      <th>beer/style</th>\n",
       "      <th>review/appearance</th>\n",
       "      <th>review/aroma</th>\n",
       "      <th>review/palate</th>\n",
       "      <th>review/taste</th>\n",
       "      <th>review/overall</th>\n",
       "      <th>...</th>\n",
       "      <th>review/text</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>abv</th>\n",
       "      <th>style</th>\n",
       "      <th>brewer</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>John Harvards Simcoe IPA</td>\n",
       "      <td>63836</td>\n",
       "      <td>8481.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>India Pale Ale &amp;#40;IPA&amp;#41;</td>\n",
       "      <td>4/5</td>\n",
       "      <td>6/10</td>\n",
       "      <td>3/5</td>\n",
       "      <td>6/10</td>\n",
       "      <td>13/20</td>\n",
       "      <td>...</td>\n",
       "      <td>On tap at the Springfield, PA location. Poured...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.65</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>John Harvards Simcoe IPA</td>\n",
       "      <td>63836</td>\n",
       "      <td>8481.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>India Pale Ale &amp;#40;IPA&amp;#41;</td>\n",
       "      <td>4/5</td>\n",
       "      <td>6/10</td>\n",
       "      <td>4/5</td>\n",
       "      <td>7/10</td>\n",
       "      <td>13/20</td>\n",
       "      <td>...</td>\n",
       "      <td>On tap at the John Harvards in Springfield PA....</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.65</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>John Harvards Cristal Pilsner</td>\n",
       "      <td>71716</td>\n",
       "      <td>8481.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Bohemian Pilsener</td>\n",
       "      <td>4/5</td>\n",
       "      <td>5/10</td>\n",
       "      <td>3/5</td>\n",
       "      <td>6/10</td>\n",
       "      <td>14/20</td>\n",
       "      <td>...</td>\n",
       "      <td>UPDATED: FEB 19, 2003 Springfield, PA. I've ne...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>John Harvards Fancy Lawnmower Beer</td>\n",
       "      <td>64125</td>\n",
       "      <td>8481.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Klsch</td>\n",
       "      <td>2/5</td>\n",
       "      <td>4/10</td>\n",
       "      <td>2/5</td>\n",
       "      <td>4/10</td>\n",
       "      <td>8/20</td>\n",
       "      <td>...</td>\n",
       "      <td>On tap the Springfield PA location billed as t...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>John Harvards Fancy Lawnmower Beer</td>\n",
       "      <td>64125</td>\n",
       "      <td>8481.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Klsch</td>\n",
       "      <td>2/5</td>\n",
       "      <td>4/10</td>\n",
       "      <td>2/5</td>\n",
       "      <td>4/10</td>\n",
       "      <td>8/20</td>\n",
       "      <td>...</td>\n",
       "      <td>On tap at the Springfield, PA location. Poured...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>854.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            beer/name beer/beerId  beer/brewerId beer/ABV  \\\n",
       "0            John Harvards Simcoe IPA       63836         8481.0      5.4   \n",
       "1            John Harvards Simcoe IPA       63836         8481.0      5.4   \n",
       "2       John Harvards Cristal Pilsner       71716         8481.0        5   \n",
       "3  John Harvards Fancy Lawnmower Beer       64125         8481.0      5.4   \n",
       "4  John Harvards Fancy Lawnmower Beer       64125         8481.0      5.4   \n",
       "\n",
       "                     beer/style review/appearance review/aroma review/palate  \\\n",
       "0  India Pale Ale &#40;IPA&#41;               4/5         6/10           3/5   \n",
       "1  India Pale Ale &#40;IPA&#41;               4/5         6/10           4/5   \n",
       "2             Bohemian Pilsener               4/5         5/10           3/5   \n",
       "3                         Klsch               2/5         4/10           2/5   \n",
       "4                         Klsch               2/5         4/10           2/5   \n",
       "\n",
       "  review/taste review/overall  ...  \\\n",
       "0         6/10          13/20  ...   \n",
       "1         7/10          13/20  ...   \n",
       "2         6/10          14/20  ...   \n",
       "3         4/10           8/20  ...   \n",
       "4         4/10           8/20  ...   \n",
       "\n",
       "                                         review/text appearance aroma  palate  \\\n",
       "0  On tap at the Springfield, PA location. Poured...        0.8   0.6     0.6   \n",
       "1  On tap at the John Harvards in Springfield PA....        0.8   0.6     0.8   \n",
       "2  UPDATED: FEB 19, 2003 Springfield, PA. I've ne...        0.8   0.5     0.6   \n",
       "3  On tap the Springfield PA location billed as t...        0.4   0.4     0.4   \n",
       "4  On tap at the Springfield, PA location. Poured...        0.4   0.4     0.4   \n",
       "\n",
       "   taste  overall  abv  style  brewer  experience  \n",
       "0    0.6     0.65  5.4      0       0       854.0  \n",
       "1    0.7     0.65  5.4      0       0       499.0  \n",
       "2    0.6     0.70  5.0      1       0        23.0  \n",
       "3    0.4     0.40  5.4      2       0       503.0  \n",
       "4    0.4     0.40  5.4      2       0       854.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beer_brewers = df_full['beer/brewerId'].unique()\n",
    "beer_brewers_index = dict(zip(beer_brewers, range(len(beer_brewers))))\n",
    "df_full['brewer'] = df_full.apply(lambda row: beer_brewers_index[row['beer/brewerId']], axis=1)\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "breweries = df_full['brewer'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNet(nn.Module):\n",
    "    # feed forward network to predict rating from variables like abv, beer style, brewery, and experience\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        output_size\n",
    "    ): # initialize the model\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size,10)\n",
    "        self.linear2 = nn.Linear(10,50)\n",
    "        self.linear3 = nn.Linear(50,10)\n",
    "        self.linear4 = nn.Linear(10,output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.relu(self.linear3(x))\n",
    "        x = self.softmax(self.linear4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset with equal amounts of high, med, and low ratings\n",
    "\n",
    "NUM_SAMPLES = 24000\n",
    "high_indices = random.sample(high_rating.index.tolist(), int(NUM_SAMPLES / 3))\n",
    "med_indices = random.sample(med_rating.index.tolist(), int(NUM_SAMPLES / 3))\n",
    "low_indices = random.sample(low_rating.index.tolist(), int(NUM_SAMPLES / 3))\n",
    "\n",
    "indices = high_indices + med_indices + low_indices\n",
    "random.shuffle(indices)\n",
    "\n",
    "df = df_full.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8000, 8000, 8000]\n"
     ]
    }
   ],
   "source": [
    "features = df[['brewer', 'abv', 'style']].to_numpy()\n",
    "features_exp = df[['brewer', 'abv', 'style', 'experience']].to_numpy()\n",
    "\n",
    "overall_ratings = df['overall'].values.tolist()\n",
    "ternary_labels = np.array([2 if rating > 0.7 else (0 if rating < 0.4 else 1) for rating in overall_ratings])\n",
    "print([np.count_nonzero(ternary_labels == x) for x in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build train, validate, and test sets\n",
    "\n",
    "split_frac = 0.8\n",
    "num_features = len(features)\n",
    "train_x = features[0:int(split_frac*num_features)]\n",
    "train_x_exp = features_exp[0:int(split_frac*num_features)]\n",
    "train_y = ternary_labels[0:int(split_frac*num_features)]\n",
    "\n",
    "remaining_x = features[int(split_frac*num_features):]\n",
    "remaining_x_exp = features_exp[int(split_frac*num_features):]\n",
    "remaining_y = ternary_labels[int(split_frac*num_features):]\n",
    "\n",
    "valid_x = remaining_x[0:int(len(remaining_x)*0.5)]\n",
    "valid_x_exp = remaining_x_exp[0:int(len(remaining_x_exp)*0.5)]\n",
    "valid_y = remaining_y[0:int(len(remaining_y)*0.5)]\n",
    "\n",
    "test_x = remaining_x[int(len(remaining_x)*0.5):]\n",
    "test_x_exp = remaining_x_exp[int(len(remaining_x_exp)*0.5):]\n",
    "test_y = remaining_y[int(len(remaining_y)*0.5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "# create datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "train_data_exp = TensorDataset(torch.from_numpy(train_x_exp), torch.from_numpy(train_y))\n",
    "valid_data_exp = TensorDataset(torch.from_numpy(valid_x_exp), torch.from_numpy(valid_y))\n",
    "test_data_exp = TensorDataset(torch.from_numpy(test_x_exp), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "train_loader_exp = DataLoader(train_data_exp, shuffle=True, batch_size=batch_size)\n",
    "valid_loader_exp = DataLoader(valid_data_exp, shuffle=True, batch_size=batch_size)\n",
    "test_loader_exp = DataLoader(test_data_exp, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model params\n",
    "input_size = len(features[0])\n",
    "input_size_exp = len(features_exp[0])\n",
    "output_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function to train neural net\n",
    "def train_net(net, train_loader, valid_loader):\n",
    "    print(net)\n",
    "    # loss and optimization functions\n",
    "    lr=1e-3\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    # training params\n",
    "    epochs = 1000\n",
    "    print_every = 100\n",
    "    epoch_accuracies = []\n",
    "\n",
    "    net.train()\n",
    "    # train for some number of epochs\n",
    "    for e in range(epochs):\n",
    "        epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "\n",
    "        # batch loop\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.type(torch.FloatTensor)\n",
    "            output = net(inputs) # Get prediction probabilities from model\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = loss_fn(output,labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # update epoch accuracy\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            mask = preds[preds == labels]\n",
    "            train_correct = len(mask)\n",
    "            train_total = len(labels)\n",
    "\n",
    "            epoch_correct += train_correct\n",
    "            epoch_total += train_total\n",
    "\n",
    "            # Adjust accordingly with the optimizer\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # print stats\n",
    "        if (e+1) % print_every == 0:\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            for inputs, labels in valid_loader:\n",
    "                inputs = inputs.type(torch.FloatTensor)\n",
    "                output = net(inputs)\n",
    "\n",
    "                val_loss = loss_fn(output, labels)\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "                preds = torch.argmax(output, dim=1)\n",
    "                mask = preds[preds == labels]\n",
    "                val_correct += len(mask)\n",
    "                val_total += len(labels)\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Accuracy: {:.6f}...\".format(float(epoch_correct)/epoch_total),\n",
    "                  \"Val Accuracy: {:.6f}...\".format(float(val_correct) / val_total),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "\n",
    "        epoch_accuracies.append(float(epoch_correct) / epoch_total)\n",
    "    for i in range(len(epoch_accuracies)):\n",
    "        if (i%50 == 0):\n",
    "            print(\"Epoch #{} Accuracy: {:.3f}%\".format(i + 1, epoch_accuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test neural net\n",
    "def test_net(net, test_loader):\n",
    "    # test model\n",
    "    num_correct = 0\n",
    "\n",
    "    net.eval()\n",
    "    # iterate over test data\n",
    "    for inputs, labels in test_loader:\n",
    "        # get predicted outputs\n",
    "        inputs = inputs.type(torch.FloatTensor)\n",
    "        output = net(inputs)\n",
    "\n",
    "        # get predicted class from output probabilities\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        mask = preds[preds == labels]\n",
    "        num_correct += len(mask)\n",
    "\n",
    "    # test accuracy\n",
    "    print(\"Test accuracy: {:.3f}\".format(float(num_correct)/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedForwardNet(\n",
      "  (linear1): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (linear2): Linear(in_features=10, out_features=50, bias=True)\n",
      "  (linear3): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (linear4): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Epoch: 100/1000... Accuracy: 0.335208... Val Accuracy: 0.322917... Val Loss: 1.098989\n",
      "Epoch: 200/1000... Accuracy: 0.333073... Val Accuracy: 0.329583... Val Loss: 1.098897\n",
      "Epoch: 300/1000... Accuracy: 0.338802... Val Accuracy: 0.350417... Val Loss: 1.098583\n",
      "Epoch: 400/1000... Accuracy: 0.531823... Val Accuracy: 0.534583... Val Loss: 0.991501\n",
      "Epoch: 500/1000... Accuracy: 0.540573... Val Accuracy: 0.501250... Val Loss: 1.007564\n",
      "Epoch: 600/1000... Accuracy: 0.545521... Val Accuracy: 0.557500... Val Loss: 0.978145\n",
      "Epoch: 700/1000... Accuracy: 0.559688... Val Accuracy: 0.545833... Val Loss: 0.976331\n",
      "Epoch: 800/1000... Accuracy: 0.571146... Val Accuracy: 0.551667... Val Loss: 0.969878\n",
      "Epoch: 900/1000... Accuracy: 0.587083... Val Accuracy: 0.570000... Val Loss: 0.952793\n",
      "Epoch: 1000/1000... Accuracy: 0.587448... Val Accuracy: 0.558750... Val Loss: 0.960908\n",
      "Epoch #1 Accuracy: 33.078%\n",
      "Epoch #51 Accuracy: 33.156%\n",
      "Epoch #101 Accuracy: 33.177%\n",
      "Epoch #151 Accuracy: 33.323%\n",
      "Epoch #201 Accuracy: 33.542%\n",
      "Epoch #251 Accuracy: 33.229%\n",
      "Epoch #301 Accuracy: 33.979%\n",
      "Epoch #351 Accuracy: 44.359%\n",
      "Epoch #401 Accuracy: 53.083%\n",
      "Epoch #451 Accuracy: 53.375%\n",
      "Epoch #501 Accuracy: 53.698%\n",
      "Epoch #551 Accuracy: 54.302%\n",
      "Epoch #601 Accuracy: 54.172%\n",
      "Epoch #651 Accuracy: 55.714%\n",
      "Epoch #701 Accuracy: 56.802%\n",
      "Epoch #751 Accuracy: 56.531%\n",
      "Epoch #801 Accuracy: 57.000%\n",
      "Epoch #851 Accuracy: 57.307%\n",
      "Epoch #901 Accuracy: 58.344%\n",
      "Epoch #951 Accuracy: 57.792%\n"
     ]
    }
   ],
   "source": [
    "# train network that doesn't use user experience\n",
    "\n",
    "net = FeedForwardNet(input_size, output_size)\n",
    "train_net(net, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.578\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_net(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedForwardNet(\n",
      "  (linear1): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (linear2): Linear(in_features=10, out_features=50, bias=True)\n",
      "  (linear3): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (linear4): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Epoch: 100/1000... Accuracy: 0.336458... Val Accuracy: 0.324583... Val Loss: 1.226875\n",
      "Epoch: 200/1000... Accuracy: 0.527969... Val Accuracy: 0.522500... Val Loss: 0.995432\n",
      "Epoch: 300/1000... Accuracy: 0.575833... Val Accuracy: 0.560833... Val Loss: 0.979235\n",
      "Epoch: 400/1000... Accuracy: 0.575052... Val Accuracy: 0.560000... Val Loss: 0.971382\n",
      "Epoch: 500/1000... Accuracy: 0.594740... Val Accuracy: 0.585833... Val Loss: 0.941567\n",
      "Epoch: 600/1000... Accuracy: 0.592812... Val Accuracy: 0.583750... Val Loss: 0.948661\n",
      "Epoch: 700/1000... Accuracy: 0.598958... Val Accuracy: 0.577500... Val Loss: 0.944894\n",
      "Epoch: 800/1000... Accuracy: 0.604167... Val Accuracy: 0.587917... Val Loss: 0.940480\n",
      "Epoch: 900/1000... Accuracy: 0.601667... Val Accuracy: 0.585417... Val Loss: 0.950321\n",
      "Epoch: 1000/1000... Accuracy: 0.602083... Val Accuracy: 0.578333... Val Loss: 0.946964\n",
      "Epoch #1 Accuracy: 33.505%\n",
      "Epoch #51 Accuracy: 33.286%\n",
      "Epoch #101 Accuracy: 33.656%\n",
      "Epoch #151 Accuracy: 36.932%\n",
      "Epoch #201 Accuracy: 53.484%\n",
      "Epoch #251 Accuracy: 56.417%\n",
      "Epoch #301 Accuracy: 57.599%\n",
      "Epoch #351 Accuracy: 58.193%\n",
      "Epoch #401 Accuracy: 57.083%\n",
      "Epoch #451 Accuracy: 59.000%\n",
      "Epoch #501 Accuracy: 59.219%\n",
      "Epoch #551 Accuracy: 57.224%\n",
      "Epoch #601 Accuracy: 59.245%\n",
      "Epoch #651 Accuracy: 60.224%\n",
      "Epoch #701 Accuracy: 59.990%\n",
      "Epoch #751 Accuracy: 60.042%\n",
      "Epoch #801 Accuracy: 60.193%\n",
      "Epoch #851 Accuracy: 60.776%\n",
      "Epoch #901 Accuracy: 60.776%\n",
      "Epoch #951 Accuracy: 60.078%\n"
     ]
    }
   ],
   "source": [
    "# train network that does use user experience\n",
    "net_exp = FeedForwardNet(input_size_exp, output_size)\n",
    "train_net(net_exp, train_loader_exp, valid_loader_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.583\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_net(net_exp, test_loader_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
